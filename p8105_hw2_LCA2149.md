p8105_hw2_LCA2149
================
2025-09-23

## Question 1

``` r
library(tidyverse)
library(readxl)
library(haven)
```

Let’s import the pols-month dataset and break the variable mon into
integer variables year, month, and day; replace month number with month
name; create a president variable taking values gop and dem, and remove
prez_dem and prez_gop; and remove the day variable.

``` r
polsmonth_df=
  read_csv("data/pols-month.csv") |>
  separate(
    mon, into = c ("year", "month", "day"), sep = "-") |>
      mutate(
        year = as.integer(year),
        month = month.name[as.integer(month)],
        day=as.integer(day),
        president = case_when (
          prez_gop == 1 ~ "gop",
          prez_dem == 1 ~ "dem"
        )
      ) |>
      select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Now let’s import snp.csv clean it up.

``` r
snp_df=
  read_csv("data/snp.csv") |>
     mutate(
    date = mdy(date),
    date = as.Date(ifelse(year(date) > 2025, date - years(100), date)),
    year = year(date),
    month = month.name[month(date)]
  ) |>
  select(year, month, everything(), -date) |>
  arrange(year, match(month, month.name))
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Now let’s import unemployment.csv and clean it up.

``` r
unemployment_df=
  read_csv("data/unemployment.csv") |>
  pivot_longer(
    cols = -Year,               
    names_to = "month",         
    values_to = "unemployment"  
  ) |>
  mutate(
 month = month.name[match(month, month.abb)],
 year = Year,
  ) |>
  select(year, month, unemployment) |>
  arrange(year, month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Let’s merge all three datasets now.

``` r
fivethirtyeight1_df =
  left_join(snp_df, polsmonth_df, by=c("year", "month"))
```

``` r
fivethirtyeight_df = 
  left_join(fivethirtyeight1_df, unemployment_df, by=c("year", "month"))
view(fivethirtyeight_df)
```

The three datasets from the `fivethirtyeight_df` data are all
time-series datasets that compare data over time. The `polsmonth_df`
data set summarizes monthly political standings. It includes date,
number of republican governors, number of republican senators, number of
republican represetatives in congress, number of democratic governors,
number of democratic senators, number of democratic representatives in
congress, and party affiliation of the president. I split the date into
month and year and created a president variable. The `snp_df` dataset
summarizes daily stockmarket data including the date and value at close.
I converted the date here. The `unemployment_df` dataset summarizes
unemployment rates across month and year. I reshaped this from a long to
wide format and converted month abbreviations to full names. After
merging all three datasets by year and month, the resulting dataset
`fivethirtyeight_df` contains information on politics, stock market
value, and unemployment for each month in the overlapping years. The
data ranges from 1950-2015. This new dataset contains 11 variables x 787
rows. Important variables include: year, month, stock value close,
unemployment rate, president political party, and various
governor/senator count data points.

## Question 2

Read and clean the Mr. Trash Wheel sheet

``` r
library(readxl)

Mrtrash_df=
  read_excel("data/TrashWheelCollectionDataNew.xlsx", sheet="Mr. Trash Wheel", range= "A2:N709", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  mutate(
    sports_balls=as.integer(round(sports_balls)),
    year = as.integer(year),
    dataset = "Mr"
  ) 
```

Do the same for Professor Trash Wheel

``` r
Proftrash_df=
  read_excel("data/TrashWheelCollectionDataNew.xlsx", sheet="Professor Trash Wheel", range= "A2:M134", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
   mutate(dataset = "Professor")
```

And Gwynnda

``` r
Gwynnda_df=
  read_excel("data/TrashWheelCollectionDataNew.xlsx", sheet="Gwynns Falls Trash Wheel", range= "A2:L351", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
   mutate(dataset = "Gwynnda") 
```

Merge all three datasets.

``` r
trash_df <- bind_rows(Mrtrash_df, Proftrash_df, Gwynnda_df)
```

Compute total weight of trash collected by prof trash wheel

``` r
sum(Proftrash_df$weight_tons) 
```

    ## [1] 282.26

Compute the total number of cigarette butts collected by Gwynnda in June
2022.

``` r
sum(Gwynnda_df$cigarette_butts[
  Gwynnda_df$month == "June" & Gwynnda_df$year == 2022]) 
```

    ## [1] 18120

The combined `trash_df` dataset combines the following three datasets
`Mrtrash_df`, `Proftrash_df`, and `Gwynnda_df` for a combined 15 columns
and 1,032 observations. This dataset combines three Baltimore waterway
trash collection sites: Mr. Trash Wheel, Professor Trash Wheel, and
Gwynnda. Examples of key variables include weight_lbs (weight of trash
collected), cigarette_butts, and sports_balls. Across the dataset,
Professor Trash Wheel collected a total of 282.26 pounds of trash.
Focusing on Gwynnda in June 2022, a total of 18,120 cigarette butts were
collected.

## Question 3

Import Zip Code data

``` r
Zipcode_df=
  read_csv("data/Zip Codes.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() 
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Import Zip_zori

``` r
Zipzori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", 
           na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  pivot_longer(
    cols=starts_with("x20"),
    names_to="date",
    values_to="zillow_value"
  ) |>
   filter(zillow_value != 0) |>
  rename(
  zip_code=region_name)  |>
  mutate(
    date = as.Date(gsub("x", "", gsub("_", "-", date)))
  ) 
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merge

``` r
Zillow_df =
  left_join(Zipzori_df, Zipcode_df, by=c("zip_code")) |>
  select(date, zip_code, neighborhood, county, city, state, zillow_value, everything(), -state_name, -county_name)
```

    ## Warning in left_join(Zipzori_df, Zipcode_df, by = c("zip_code")): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 2759 of `x` matches multiple rows in `y`.
    ## ℹ Row 256 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

Describe dataset

``` r
nrow(Zillow_df)
```

    ## [1] 10677

``` r
n_distinct(Zillow_df$zip_code)
```

    ## [1] 149

``` r
n_distinct(Zillow_df$neighborhood)
```

    ## [1] 43

``` r
missing_zips = setdiff(Zipcode_df$zip_code, Zipzori_df$zip_code)
missing_zips
```

    ##   [1] 10464 10474 10475 10499 10550 10704 10705 10803 11202 11224 11239 11241
    ##  [13] 11242 11243 11245 11247 11251 11252 11256 10008 10020 10041 10043 10045
    ##  [25] 10047 10048 10055 10072 10080 10081 10082 10087 10101 10102 10103 10104
    ##  [37] 10105 10106 10107 10108 10109 10110 10111 10112 10113 10114 10115 10116
    ##  [49] 10117 10118 10119 10120 10121 10122 10123 10124 10125 10126 10129 10130
    ##  [61] 10131 10132 10133 10138 10149 10150 10151 10152 10153 10154 10155 10156
    ##  [73] 10157 10158 10159 10160 10161 10163 10164 10165 10166 10167 10168 10169
    ##  [85] 10170 10171 10172 10173 10174 10175 10176 10177 10178 10179 10185 10197
    ##  [97] 10199 10213 10242 10249 10256 10259 10260 10261 10265 10268 10269 10270
    ## [109] 10271 10272 10273 10274 10275 10276 10277 10278 10279 10281 10285 10286
    ## [121] 10292 11001 11004 11005 11040 11096 11351 11352 11359 11362 11363 11371
    ## [133] 11380 11381 11386 11405 11411 11412 11413 11414 11416 11417 11419 11420
    ## [145] 11421 11422 11423 11424 11425 11427 11428 11429 11430 11431 11433 11436
    ## [157] 11439 11451 11499 11559 11580 11690 11694 11695 11697 10302 10307 10309
    ## [169] 10310 10311 10313

COVID rental drop

``` r
library(dplyr)
library(stringr)

covid_drop <- Zillow_df |>
  filter(str_starts(date, "2020-01") | str_starts(date, "2021-01")) |>
  group_by(zip_code, county, neighborhood) |>
  summarise(
    rent_2020 = zillow_value[str_starts(date, "2020-01")],
    rent_2021 = zillow_value[str_starts(date, "2021-01")],
    drop = rent_2021 - rent_2020,
    .groups = "drop"
  ) |>
  arrange(drop) |>
  slice_head(n = 10)
```

    ## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in
    ## dplyr 1.1.0.
    ## ℹ Please use `reframe()` instead.
    ## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`
    ##   always returns an ungrouped data frame and adjust accordingly.
    ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
    ## generated.

``` r
covid_drop
```

    ## # A tibble: 10 × 6
    ##    zip_code county   neighborhood                  rent_2020 rent_2021  drop
    ##       <dbl> <chr>    <chr>                             <dbl>     <dbl> <dbl>
    ##  1    10007 New York Lower Manhattan                   6334.     5422. -913.
    ##  2    10069 New York <NA>                              4623.     3875. -748.
    ##  3    10009 New York Lower East Side                   3406.     2692. -714.
    ##  4    10016 New York Gramercy Park and Murray Hill     3731.     3019. -712.
    ##  5    10001 New York Chelsea and Clinton               4108.     3398. -710.
    ##  6    10002 New York Lower East Side                   3645.     2935. -710.
    ##  7    10004 New York Lower Manhattan                   3150.     2444. -706.
    ##  8    10038 New York Lower Manhattan                   3573.     2876. -698.
    ##  9    10012 New York Greenwich Village and Soho        3629.     2942. -686.
    ## 10    10010 New York Gramercy Park and Murray Hill     3697.     3012. -685.

The `Zillow_df` dataset contains 10,677 observations, 149 distinct zip
codes, and 43 neighborhoods. There were many excluded zipcodes, about
171 to be exact. These excluded zipcodes were excluded for various
reasons including being business only zipcodes,
commercial/governmenta/industry areas. Some specific examples include
the two airport zipcodes that were excluded, 11430 (JFK) and 11371
(LaGuardia). Furthermore, 10550 and 10704 are both outside of the five
boroughs. From January 2020 to January 2021 there were major price
reductions in rent. As we see above, the largest 10 price drops occured
in Manhattan ranging from a decrease of \$913 to \$685.
