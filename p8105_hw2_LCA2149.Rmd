---
title: "p8105_hw2_LCA2149"
output: github_document
date: "2025-09-23"
---

## Question 1

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(haven)
```

Let's import the pols-month dataset and break the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
polsmonth_df=
  read_csv("data/pols-month.csv") |>
  separate(
    mon, into = c ("year", "month", "day"), sep = "-") |>
      mutate(
        year = as.integer(year),
        month = month.name[as.integer(month)],
        day=as.integer(day),
        president = case_when (
          prez_gop == 1 ~ "gop",
          prez_dem == 1 ~ "dem"
        )
      ) |>
      select(-prez_dem, -prez_gop, -day)
```

Now let's import snp.csv clean it up.
```{r}
snp_df=
  read_csv("data/snp.csv") |>
     mutate(
    date = mdy(date),
    date = as.Date(ifelse(year(date) > 2025, date - years(100), date)),
    year = year(date),
    month = month.name[month(date)]
  ) |>
  select(year, month, everything(), -date) |>
  arrange(year, match(month, month.name))
```

Now let's import unemployment.csv and clean it up.
```{r}
unemployment_df=
  read_csv("data/unemployment.csv") |>
  pivot_longer(
    cols = -Year,               
    names_to = "month",         
    values_to = "unemployment"  
  ) |>
  mutate(
 month = month.name[match(month, month.abb)],
 year = Year,
  ) |>
  select(year, month, unemployment) |>
  arrange(year, month)
```

Let's merge all three datasets now.
```{r}
fivethirtyeight1_df =
  left_join(snp_df, polsmonth_df, by=c("year", "month"))
```

```{r}
fivethirtyeight_df = 
  left_join(fivethirtyeight1_df, unemployment_df, by=c("year", "month"))
view(fivethirtyeight_df)
```

The three datasets from the `fivethirtyeight_df` data are all time-series datasets that compare data over time. The `polsmonth_df` data set summarizes monthly political standings. It includes date, number of republican governors, number of republican senators, number of republican represetatives in congress, number of democratic governors, number of democratic senators, number of democratic representatives in congress, and party affiliation of the president. I split the date into month and year and created a president variable. The `snp_df` dataset summarizes daily stockmarket data including the date and value at close. I converted the date here. The `unemployment_df` dataset summarizes unemployment rates across month and year. I reshaped this from a long to wide format and converted month abbreviations to full names. After merging all three datasets by year and month, the resulting dataset `fivethirtyeight_df` contains information on politics, stock market value, and unemployment for each month in the overlapping years. The data ranges from 1950-2015. This new dataset contains 11 variables x 787 rows. Important variables include: year, month, stock value close, unemployment rate, president political party, and various governor/senator count data points.


## Question 2

Read and clean the Mr. Trash Wheel sheet
```{r}
library(readxl)

Mrtrash_df=
  read_excel("data/TrashWheelCollectionData.xlsx", sheet="Mr. Trash Wheel", range= "A2:N653", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  mutate(
    sports_balls=as.integer(round(sports_balls)),
    year = as.integer(year),
    dataset = "Mr"
  ) 
```


Do the same for Professor Trash Wheel
```{r}
Proftrash_df=
  read_excel("data/TrashWheelCollectionData.xlsx", sheet="Professor Trash Wheel", range= "A2:M120", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
   mutate(dataset = "Professor")
```


And Gwynnda
```{r}
Gwynnda_df=
  read_excel("data/TrashWheelCollectionData.xlsx", sheet="Gwynnda Trash Wheel", range= "A2:L265", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
   mutate(dataset = "Gwynnda") 
```


Merge all three datasets.
```{r}
trash_df <- bind_rows(Mrtrash_df, Proftrash_df, Gwynnda_df)
```

Compute total weight of trash collected by prof trash wheel
```{r}
sum(Proftrash_df$weight_tons) 
```

Compute the total number of cigarette butts collected by Gwynnda in June 2022.
```{r}
sum(Gwynnda_df$cigarette_butts[
  Gwynnda_df$month == "June" & Gwynnda_df$year == 2022]) 
```

The combined `trash_df` dataset combines the following three datasets 
`Mrtrash_df`, `Proftrash_df`, and `Gwynnda_df` for a combined 15 columns and 
1,032 observations. This dataset combines three Baltimore waterway trash 
collection sites: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. Examples 
of key variables include weight_lbs (weight of trash collected), 
cigarette_butts, and sports_balls. Across the dataset, Professor Trash Wheel 
collected a total of 246.74 pounds of trash. Focusing on Gwynnda in June 2022, 
a total of 18,120 cigarette butts were collected.

## Question 3

Import Zip Code data
```{r}
Zipcode_df=
  read_csv("data/Zip Codes.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() 
```

Import Zip_zori
```{r}
Zipzori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", 
           na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  pivot_longer(
    cols=starts_with("x20"),
    names_to="date",
    values_to="zillow_value"
  ) |>
   filter(zillow_value != 0) |>
  rename(
  zip_code=region_name)  |>
  mutate(
    date = as.Date(gsub("x", "", gsub("_", "-", date)))
  ) 
```


Merge
```{r}
Zillow_df =
  left_join(Zipzori_df, Zipcode_df, by=c("zip_code")) |>
  select(date, zip_code, neighborhood, county, city, state, zillow_value, everything(), -state_name, -county_name)
```

Describe dataset
```{r}
nrow(Zillow_df)
n_distinct(Zillow_df$zip_code)
n_distinct(Zillow_df$neighborhood)

missing_zips = setdiff(Zipcode_df$zip_code, Zipzori_df$zip_code)
missing_zips
```

COVID rental drop
```{r}

library(dplyr)
library(stringr)

covid_drop <- Zillow_df |>
  filter(str_starts(date, "2020-01") | str_starts(date, "2021-01")) |>
  group_by(zip_code, county, neighborhood) |>
  summarise(
    rent_2020 = zillow_value[str_starts(date, "2020-01")],
    rent_2021 = zillow_value[str_starts(date, "2021-01")],
    drop = rent_2021 - rent_2020,
    .groups = "drop"
  ) |>
  arrange(drop) |>
  slice_head(n = 10)

covid_drop
```


The `Zillow_df` dataset contains 10,677 observations, 149 distinct zip codes, and 43 neighborhoods. There were many excluded zipcodes, about 171 to be exact. These excluded zipcodes were excluded for various reasons including being business only zipcodes, commercial/governmenta/industry areas. Some specific examples include the two airport zipcodes that were excluded, 11430 (JFK) and 11371 (LaGuardia). Furthermore, 10550 and 10704 are both outside of the five boroughs. From January 2020 to January 2021 there were major price reductions in rent. As we see above, the largest 10 price drops occured in Manhattan ranging from a decrease of $913 to $685.